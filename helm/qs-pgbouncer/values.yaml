# ============================================================================
# QS PgBouncer Helm Chart Configuration
# ============================================================================
#
# This Helm chart deploys PgBouncer connection poolers for PostgreSQL clusters.
# It supports multiple independent instances with separate configurations:
# - PgBouncer for Pharia cluster (transaction pooling mode)
# - PgBouncer for Temporal cluster (session pooling mode)
#
# Each PgBouncer instance can be configured independently with its own:
# - Database connections and routing
# - Resource limits and high availability
# - Monitoring and metrics collection
# - Authentication and user management
#
# For more details, see:
# - https://www.pgbouncer.org/config.html
# - https://github.com/cloudnative-pg/pgbouncer-containers

# ============================================================================
# Global Configuration
# ============================================================================

# Override the full name used for Kubernetes resources
fullnameOverride: "qs-pgbouncer"

# ============================================================================
# Helm Test Configuration
# ============================================================================
# Configuration for Helm tests that verify PgBouncer connectivity and functionality
# Note: Tests are only executed when you run 'helm test <release-name>'
tests:
  # Container image to use for connection tests
  image: "postgres:17"
  # SSL mode for PostgreSQL connections during tests
  sslMode: "prefer"

# ============================================================================
# PgBouncer Pharia Instance Configuration
# ============================================================================
# PgBouncer instance for the Pharia PostgreSQL cluster
# Uses transaction pooling mode for optimal connection reuse

pgbouncerPharia:
  # Enable or disable this PgBouncer instance
  enabled: true
  # Override the full name for this specific instance
  fullnameOverride: pgbouncer-pharia
  # Kubernetes workload type (Deployment or StatefulSet)
  kind: Deployment
  # Number of PgBouncer replica pods for high availability
  replicaCount: 3

  # === Database Configuration ===
  # Database connection settings and PgBouncer parameters
  config:
    # Database connection mappings
    # The "*" wildcard allows any database name to be routed to the target host
    databases:
      "*":
        # PostgreSQL cluster service hostname for Pharia
        host: "cluster-pharia-rw"
        # PostgreSQL service port
        port: 5432
      # pharia-os database specific configuration to avoid pg prepared statement error
      # it can also solve by adding "binary_parameters=yes" in connection string if we want to use transaction pool mode
      "pharia-os":
        # PostgreSQL cluster service hostname for Pharia
        host: "cluster-pharia-rw"
        # PostgreSQL service port
        port: 5432
        pool_mode: session
        pool_size: 20

      "dex":
        # PostgreSQL cluster service hostname for Pharia
        host: "cluster-pharia-rw"
        # PostgreSQL service port
        port: 5432
        pool_mode: session
        pool_size: 20

    # Administrative user for PgBouncer management
    adminUser: pgbouncer

    # Core PgBouncer configuration parameters
    # Reference: https://www.pgbouncer.org/config.html
    pgbouncer:
      # Connection pooling mode: transaction mode for Pharia applications
      # Transaction mode releases connections after each transaction
      pool_mode: transaction
      # SSL mode for backend PostgreSQL connections
      server_tls_sslmode: require
      # PostgreSQL parameters to ignore from client connections
      ignore_startup_parameters: extra_float_digits, jit
      # Default number of connections in the pool
      default_pool_size: 20
      # Authentication method: scram-sha-256 for secure password handling
      auth_type: scram-sha-256
      # Log new connections (0=disabled, 1=enabled)
      log_connections: 0
      # Log connection closures (0=disabled, 1=enabled)
      log_disconnections: 0
      # Log pooler errors (0=disabled, 1=enabled)
      log_pooler_errors: 1
      # Log pooler statistics (0=disabled, 1=enabled)
      log_stats: 1
      # Log file destination (stdout for container logging)
      logfile: /dev/stdout
      # Maximum number of client connections
      max_client_conn: 300

    # === Authentication Configuration ===
    # Secret management for user authentication
    # Secrets must be created separately and contain required user credentials
    # Name of secret containing admin user credentials (adminUser/adminPassword keys)
    existingAdminSecret: "pgbouncer-pharia-admin"
    # Name of secret containing userlist.txt file for user authentication
    existingUserlistSecret: "pgbouncer-pharia-userlist"

  # === Resource Configuration ===
  # CPU and memory resource limits and requests for PgBouncer pods
  resources:
    limits:
      # CPU limit
      cpu: 100m
      # Memory limit
      memory: 128Mi
    requests:
      # CPU request
      cpu: 50m
      # Memory request
      memory: 64Mi

  # === High Availability Configuration ===
  # Pod affinity and anti-affinity rules for high availability
  affinity:
    podAntiAffinity:
      # Prefer to schedule pods on different nodes to avoid single points of failure
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - pgbouncer
            - key: app.kubernetes.io/instance
              operator: In
              values:
              - pgbouncer
          # Topology key for anti-affinity (hostname separates by node)
          topologyKey: kubernetes.io/hostname

  # === Monitoring Configuration ===
  # PgBouncer metrics exporter configuration (nested under config)
  pgbouncerExporter:
    # Enable Prometheus metrics exporter sidecar
    enabled: true
    # Enable PodMonitor for Prometheus Operator (deprecated, use serviceMonitor)
    podMonitor: false

  # === Initialization Configuration ===
  # Additional init containers to run before PgBouncer starts
  extraInitContainers:
  - name: check-config
    # Lightweight image for configuration validation
    image: "alpine:latest"
    command:
      - /bin/sh
      - -c
      - |
        # Wait for userlist.txt to be available
        echo "INFO: Waiting for /etc/userlist/userlist.txt to be available..."
        max_wait=300
        wait_time=0
        while [ ! -f /etc/userlist/userlist.txt ] && [ $wait_time -lt $max_wait ]; do
          echo "userlist.txt not found, waiting... (${wait_time}s/${max_wait}s)"
          sleep 5
          wait_time=$((wait_time + 5))
        done
        if [ ! -f /etc/userlist/userlist.txt ]; then
          echo "ERROR: userlist.txt not found after ${max_wait} seconds"
          exit 127
        fi
        # Validate file is not empty
        if [ ! -s /etc/userlist/userlist.txt ]; then
          echo "ERROR: userlist.txt is empty"
          exit 127
        fi
        echo "INFO: userlist.txt is present and non-empty."
    volumeMounts:
    - name: userlist
      mountPath: /etc/userlist/

# ============================================================================
# PgBouncer Temporal Instance Configuration
# ============================================================================
# PgBouncer instance for the Temporal PostgreSQL cluster
# Uses session pooling mode to maintain connection state for Temporal workflows

pgbouncerTemporal:
  # Enable or disable this PgBouncer instance
  enabled: true
  # Override the full name for this specific instance
  fullnameOverride: pgbouncer-temporal
  # Kubernetes workload type (Deployment or StatefulSet)
  kind: Deployment
  # Number of PgBouncer replica pods for high availability
  replicaCount: 3

  # === Database Configuration ===
  # Database connection settings and PgBouncer parameters
  config:
    # Database connection mappings
    # The "*" wildcard allows any database name to be routed to the target host
    databases:
      "*":
        # PostgreSQL cluster service hostname for Temporal
        host: "cluster-temporal-rw"
        # PostgreSQL service port
        port: 5432

    # Administrative user for PgBouncer management
    adminUser: pgbouncer

    # Core PgBouncer configuration parameters
    # Reference: https://www.pgbouncer.org/config.html
    pgbouncer:
      # Connection pooling mode: session mode for Temporal's connection state requirements
      # Session mode maintains connection state and prepared statements
      pool_mode: session
      # SSL mode for backend PostgreSQL connections
      server_tls_sslmode: require
      # PostgreSQL parameters to ignore from client connections
      ignore_startup_parameters: extra_float_digits
      # Default number of connections in the pool
      default_pool_size: 20
      # Authentication method: scram-sha-256 for secure password handling
      auth_type: scram-sha-256
      # Log new connections (0=disabled, 1=enabled)
      log_connections: 0
      # Log connection closures (0=disabled, 1=enabled)
      log_disconnections: 0
      # Log pooler errors (0=disabled, 1=enabled)
      log_pooler_errors: 1
      # Log pooler statistics (0=disabled, 1=enabled)
      log_stats: 1
      # Log file destination (stdout for container logging)
      logfile: /dev/stdout
      # Maximum number of client connections
      max_client_conn: 200

    # === Authentication Configuration ===
    # Secret management for user authentication
    # Secrets must be created separately and contain required user credentials
    # Name of secret containing admin user credentials (adminUser/adminPassword keys)
    existingAdminSecret: "pgbouncer-temporal-admin"
    # Name of secret containing userlist.txt file for user authentication
    existingUserlistSecret: "pgbouncer-temporal-userlist"

  # === Resource Configuration ===
  # CPU and memory resource limits and requests for PgBouncer pods
  resources:
    limits:
      # CPU limit
      cpu: 100m
      # Memory limit
      memory: 128Mi
    requests:
      # CPU request
      cpu: 50m
      # Memory request
      memory: 64Mi

  # === High Availability Configuration ===
  # Pod affinity and anti-affinity rules for high availability
  affinity:
    podAntiAffinity:
      # Prefer to schedule pods on different nodes to avoid single points of failure
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - pgbouncer
            - key: app.kubernetes.io/instance
              operator: In
              values:
              - pgbouncer
          # Topology key for anti-affinity (hostname separates by node)
          topologyKey: kubernetes.io/hostname

  # === Pod Disruption Configuration ===
  # PodDisruptionBudget settings for controlled disruptions
  pdb:
    # Maximum number of pods that can be unavailable during disruptions
    maxUnavailable: 1

  # === Monitoring Configuration ===
  # PgBouncer metrics exporter configuration (nested under config)
  pgbouncerExporter:
    # Enable Prometheus metrics exporter sidecar
    enabled: true
    # Enable PodMonitor for Prometheus Operator (deprecated, use serviceMonitor)
    podMonitor: false

  # === Initialization Configuration ===
  # Additional init containers to run before PgBouncer starts
  extraInitContainers:
  - name: check-config
    # Lightweight image for configuration validation
    image: "alpine:latest"
    command:
      - /bin/sh
      - -c
      - |
        # Wait for userlist.txt to be available
        echo "INFO: Waiting for /etc/userlist/userlist.txt to be available..."
        max_wait=300
        wait_time=0
        while [ ! -f /etc/userlist/userlist.txt ] && [ $wait_time -lt $max_wait ]; do
          echo "userlist.txt not found, waiting... (${wait_time}s/${max_wait}s)"
          sleep 5
          wait_time=$((wait_time + 5))
        done
        if [ ! -f /etc/userlist/userlist.txt ]; then
          echo "ERROR: userlist.txt not found after ${max_wait} seconds"
          exit 127
        fi
        # Validate file is not empty
        if [ ! -s /etc/userlist/userlist.txt ]; then
          echo "ERROR: userlist.txt is empty"
          exit 127
        fi
        echo "INFO: userlist.txt is present and non-empty."
    volumeMounts:
    - name: userlist
      mountPath: /etc/userlist/
